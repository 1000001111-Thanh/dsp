{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5807228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746781684.292198   70065 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746781684.303833   70065 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746781684.325254   70065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746781684.325283   70065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746781684.325285   70065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746781684.325287   70065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0 # Use \"\" to use the CPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import sionna.phy\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# Avoid warnings from TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "sionna.phy.config.seed = 42 # Set seed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c3dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src import SystemConfig, UeConfig, MyConfig, MySimulator, MyPUSCHConfig, tic, toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e93f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.my_pusch_config import MyPUSCHConfig\n",
    "from src.my_encoder import MyTBEncoder\n",
    "from src.my_decoder import MyTBDecoder\n",
    "\n",
    "from sionna.phy.mapping import BinarySource, Mapper\n",
    "from sionna.phy.nr import PUSCHPilotPattern, LayerMapper, LayerDemapper, PUSCHLSChannelEstimator\n",
    "from sionna.phy.ofdm import ResourceGrid, ResourceGridMapper, LinearDetector\n",
    "from sionna.phy.nr.utils import generate_prng_seq\n",
    "from sionna.phy.channel import AWGN, OFDMChannel, gen_single_sector_topology as gen_topology\n",
    "from sionna.phy.mimo import StreamManagement\n",
    "from sionna.phy.channel.tr38901 import Antenna, AntennaArray, UMi, UMa, CDL\n",
    "from sionna.phy import Block\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20373bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_cfg = SystemConfig(\n",
    "    NCellId=442\n",
    ")\n",
    "ue_cfg = UeConfig(NPrb=23)\n",
    "my_cfg = MyConfig(sys_cfg, ue_cfg)\n",
    "my_pusch_cfg = MyPUSCHConfig(my_config=my_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ec1acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrier Configuration\n",
      "=====================\n",
      "cyclic_prefix : normal\n",
      "cyclic_prefix_length : 2.3437500000000002e-06\n",
      "frame_duration : 0.01\n",
      "frame_number : 0\n",
      "kappa : 64.0\n",
      "mu : 1\n",
      "n_cell_id : 442\n",
      "n_size_grid : 162\n",
      "n_start_grid : 0\n",
      "num_slots_per_frame : 20\n",
      "num_slots_per_subframe : 2\n",
      "num_symbols_per_slot : 14\n",
      "slot_number : 4\n",
      "sub_frame_duration : 0.001\n",
      "subcarrier_spacing : 30\n",
      "t_c : 5.086263020833334e-10\n",
      "t_s : 3.2552083333333335e-08\n",
      "\n",
      "PUSCH Configuration\n",
      "===================\n",
      "dmrs_grid : shape (1, 276, 14)\n",
      "dmrs_grid_precoded : shape ()\n",
      "dmrs_mask : shape (276, 14)\n",
      "dmrs_symbol_indices : [3, 11]\n",
      "first_resource_block : 0\n",
      "first_subcarrier : 0\n",
      "frequency_hopping : neither\n",
      "l : [3, 11]\n",
      "l_0 : 3\n",
      "l_bar : [3, 11]\n",
      "l_d : 14\n",
      "l_prime : [0]\n",
      "l_ref : 0\n",
      "mapping_type : A\n",
      "n : shape (69,)\n",
      "n_rnti : 20002\n",
      "n_size_bwp : 162\n",
      "n_start_bwp : 0\n",
      "num_antenna_ports : 1\n",
      "num_coded_bits : 6624\n",
      "num_layers : 1\n",
      "num_ov : 0\n",
      "num_res_per_prb : 144\n",
      "num_resource_blocks : 23\n",
      "num_subcarriers : 276\n",
      "phy_cell_id : 442\n",
      "precoding : non-codebook\n",
      "precoding_matrix : None\n",
      "symbol_allocation : [0, 14]\n",
      "tb_size : 808\n",
      "tpmi : 0\n",
      "transform_precoding : False\n",
      "\n",
      "PUSCH DMRS Configuration\n",
      "========================\n",
      "additional_position : 1\n",
      "allowed_dmrs_ports : [0, 1, 2, 3]\n",
      "beta : 1.4142135623730951\n",
      "cdm_groups : [0]\n",
      "config_type : 1\n",
      "deltas : [0]\n",
      "dmrs_port_set : [0]\n",
      "length : 1\n",
      "n_id : [442, 442]\n",
      "n_scid : 0\n",
      "num_cdm_groups_without_data : 2\n",
      "type_a_position : 3\n",
      "w_f : [[1]\n",
      " [1]]\n",
      "w_t : [[1]\n",
      " [1]]\n",
      "\n",
      "Transport Block Configuration\n",
      "=============================\n",
      "channel_type : PUSCH\n",
      "mcs_index : 0\n",
      "mcs_table : 1\n",
      "n_id : 442\n",
      "num_bits_per_symbol : 2\n",
      "target_coderate : 0.1171875\n",
      "tb_scaling : 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_pusch_cfg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4876dad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517473140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pusch_cfg.c_init(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32b96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @tf.function(input_signature=[tf.TensorSpec([], tf.int32) for _ in range(5)],\n",
    "# #     jit_compile=True)\n",
    "# def c_init_tf(l, n_id, n_scid, slot_number, num_symbols_per_slot):\n",
    "#     \"\"\"TensorFlow version of c_init from 3GPP 38.211\"\"\"\n",
    "#     term1 = 2**17 * (\n",
    "#         num_symbols_per_slot * slot_number + l + 1\n",
    "#     ) * (2 * n_id + 1)\n",
    "#     term2 = 2**17 * 0\n",
    "#     term3 = 2 * n_id + n_scid\n",
    "#     print(term1,term2,term3)\n",
    "#     c_init = tf.math.mod(term1 + term2 + term3, 2**31)\n",
    "    \n",
    "#     return c_init\n",
    "\n",
    "#     # print(\"num_symbols_per_slot\", num_symbols_per_slot, \"slot_number\", slot_number, \"n_id\", n_id, \"n_scid_bar\", n_scid)\n",
    "\n",
    "#     # lambda_bar = tf.constant(0, dtype=tf.float32)\n",
    "#     # l = tf.cast(l, tf.int64)\n",
    "#     # n_id = tf.cast(n_id, tf.int64)\n",
    "#     # n_scid = tf.cast(n_scid, tf.int64)\n",
    "#     # slot_number = tf.cast(slot_number, tf.int64)\n",
    "#     # num_symbols_per_slot = tf.cast(num_symbols_per_slot, tf.int64)\n",
    "\n",
    "#     # term1 = tf.constant(2**17, dtype=tf.int64) * (\n",
    "#     #     num_symbols_per_slot * slot_number + l + 1\n",
    "#     # ) * (2 * n_id + 1)\n",
    "\n",
    "#     # term2 = tf.constant(2**17, dtype=tf.int64) * tf.cast(tf.floor(lambda_bar / 2), tf.int64)\n",
    "\n",
    "#     # term3 = 2 * n_id + n_scid\n",
    "\n",
    "#     # print(\"terms\", term1, term2, term3)\n",
    "\n",
    "#     # c_init = (term1 + term2 + term3) % tf.constant(2**31, dtype=tf.int64)\n",
    "#     # print(\"c_init\", c_init)\n",
    "#     # return tf.cast(c_init, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa56fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_pusch_config = my_pusch_cfg.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f6d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746781688.417945   70065 service.cc:152] XLA service 0x3a0db860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746781688.417987   70065 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1746781688.564675   70065 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 14, 276), dtype=complex64, numpy=\n",
       "array([[[[ 0.+0.j,  0.+0.j,  0.+0.j, ...,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "         [ 0.+0.j,  0.+0.j,  0.+0.j, ...,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "         [ 0.+0.j,  0.+0.j,  0.+0.j, ...,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "         ...,\n",
       "         [-1.+1.j,  0.+0.j,  1.-1.j, ...,  0.+0.j,  1.+1.j,  0.+0.j],\n",
       "         [ 0.+0.j,  0.+0.j,  0.+0.j, ...,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "         [ 0.+0.j,  0.+0.j,  0.+0.j, ...,  0.+0.j,  0.+0.j,  0.+0.j]]]],\n",
       "      dtype=complex64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_simulator = MySimulator(my_pusch_cfg)\n",
    "my_simulator.reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b6db59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394.0, 3321.0, (-8.485285-20.242645j))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, c, x = my_simulator(1, prng_seed=20044, return_items=('b', 'c', 'x'))\n",
    "np.sum(b), np.sum(c), np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a703a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import random\n",
    "import os\n",
    "\n",
    "class MyWriter:\n",
    "    def __init__(self, num_shards=256,\n",
    "                 samples_per_shard=1024,\n",
    "                 output_dir=\"tfrecords\",\n",
    "                 isTempfile=False):\n",
    "\n",
    "        self.samples_per_shard = samples_per_shard\n",
    "        self.num_shards = num_shards\n",
    "\n",
    "        self.output_dir = output_dir\n",
    "        if isTempfile:\n",
    "            self.temp_dir = tempfile.TemporaryDirectory()\n",
    "            self.output_dir = os.path.join(self.temp_dir.name, output_dir)\n",
    "        \n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def _serialize_example(self, feature_tensors):\n",
    "        def _bytes_feature(tensor):\n",
    "            return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(tensor).numpy()]))\n",
    "        \n",
    "        # Tạo dictionary feature từ danh sách tên và tensor tương ứng\n",
    "        feature_dict = {\n",
    "            name: _bytes_feature(tensor) \n",
    "            for name, tensor in zip(self.return_items, feature_tensors)\n",
    "        }\n",
    "        return tf.train.Example(features=tf.train.Features(feature=feature_dict)).SerializeToString()\n",
    "\n",
    "    # @tf.function(jit_compile=True)\n",
    "    # def update_fn(rnti, slot_num, pci, rb_start):\n",
    "            \n",
    "    @tf.function(jit_compile=True)\n",
    "    def _get_example(self, simulator):\n",
    "        bz = 1\n",
    "        b, c, y, x, h = simulator(bz, return_items=('b', 'c', 'y', 'x', 'h'))\n",
    "        r = simulator.get_r_rg(bz)\n",
    "        c = simulator.get_c_rg(c)\n",
    "        \n",
    "        output_map = {\n",
    "            'b': b[0],\n",
    "            'c': c[0],\n",
    "            'y': y[0],\n",
    "            'x': x[0],\n",
    "            'r': r[0],\n",
    "            'h': h[0]\n",
    "        }\n",
    "        return tuple(output_map[item] for item in self.return_items)\n",
    "\n",
    "    def _write_shard(self, shard_id, progress_callback, simulator):\n",
    "        shard_path = os.path.join(self.output_dir, f\"data-{shard_id:04d}-of-{self.num_shards:04d}.tfrecord\")\n",
    "        buffer = []\n",
    "        with tf.io.TFRecordWriter(shard_path) as tfwriter:\n",
    "            for _ in range(self.samples_per_shard):\n",
    "                # tic()\n",
    "                # Lấy tất cả các tensor từ simulator\n",
    "                simulator.update(rnti=1230+shard_id,\n",
    "                        slot_num=[4,5,14,15][shard_id%4],\n",
    "                        pci=100+shard_id,\n",
    "                        rb_start=12\n",
    "                )\n",
    "                # toc(\"total update\")\n",
    "                \n",
    "                # tic()\n",
    "                example_tensors = self._get_example(simulator)\n",
    "                # toc(\"get example\")\n",
    "\n",
    "                # tf.print(\"=======================\")\n",
    "                # Serialize và ghi vào buffer\n",
    "                serialized = self._serialize_example(example_tensors)\n",
    "                buffer.append(serialized)\n",
    "\n",
    "                # Ghi buffer khi đủ 256 mẫu\n",
    "                if len(buffer) == 256:\n",
    "                    for example in buffer:\n",
    "                        tfwriter.write(example)\n",
    "                        progress_callback()\n",
    "                    buffer.clear()\n",
    "\n",
    "            # Ghi phần còn lại trong buffer\n",
    "            for example in buffer:\n",
    "                tfwriter.write(example)\n",
    "                progress_callback()\n",
    "            \n",
    "\n",
    "    def write(self, simulator, return_items):        \n",
    "        self.return_items = return_items\n",
    "\n",
    "        simulator = simulator.clone()\n",
    "        _ = simulator(1)  # Khởi tạo simulator\n",
    "        \n",
    "        original_stdout = sys.stdout\n",
    "        with open('output.txt', 'w') as f:\n",
    "            sys.stdout = f\n",
    "            simulator.pusch_config.show()\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "        total_samples = self.num_shards * self.samples_per_shard\n",
    "        pbar = tqdm(total=total_samples, desc=\"Generating TFRecords\", unit=\" sample\")\n",
    "        \n",
    "        def progress_callback_gen():\n",
    "            # pass\n",
    "            return lambda: pbar.update(1)\n",
    "\n",
    "        # Gọi trực tiếp _write_shard cho từng shard\n",
    "        for shard_id in range(self.num_shards):\n",
    "            progress_callback = progress_callback_gen()\n",
    "            self._write_shard(shard_id, progress_callback, simulator)\n",
    "\n",
    "        # pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6e96f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf0516e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = MyWriter(num_shards=4, samples_per_shard=32, output_dir=\"tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93379009",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "writer.write(simulator=my_simulator, return_items=('b', 'c', 'y', 'x', 'r', 'h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "103a043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(\n",
    "    input_signature=[\n",
    "        tf.TensorSpec([], tf.int32),\n",
    "        tf.TensorSpec([], tf.int32)\n",
    "    ],\n",
    "    jit_compile=True)\n",
    "def generate_prng_seq_tf(length, c_init):\n",
    "    n_seq = 31\n",
    "    n_c = 1600\n",
    "    total_len = length + n_c + n_seq\n",
    "\n",
    "    # Convert c_init to 31-bit tensor (LSB first)\n",
    "    c_init_bits = tf.bitwise.bitwise_and(\n",
    "        tf.bitwise.right_shift(c_init, tf.range(n_seq, dtype=tf.int32)),\n",
    "        1\n",
    "    )\n",
    "\n",
    "    # Initialize x1 and x2 as TensorArrays\n",
    "    x1 = tf.TensorArray(dtype=tf.int32, size=total_len, dynamic_size=False, clear_after_read=False)\n",
    "    x2 = tf.TensorArray(dtype=tf.int32, size=total_len, dynamic_size=False, clear_after_read=False)\n",
    "\n",
    "    # Set initial conditions\n",
    "    x1 = x1.write(0, 1)\n",
    "    for i in range(1, n_seq):\n",
    "        x1 = x1.write(i, 0)\n",
    "    for i in range(n_seq):\n",
    "        x2 = x2.write(i, c_init_bits[i])\n",
    "\n",
    "    # Define the loop body\n",
    "    def body(idx, x1, x2):\n",
    "        x1_val = tf.bitwise.bitwise_and(x1.read(idx + 3) + x1.read(idx), 1)\n",
    "        x2_val = tf.bitwise.bitwise_and(\n",
    "            x2.read(idx + 3) + x2.read(idx + 2) + x2.read(idx + 1) + x2.read(idx),\n",
    "            1\n",
    "        )\n",
    "        x1 = x1.write(idx + n_seq, x1_val)\n",
    "        x2 = x2.write(idx + n_seq, x2_val)\n",
    "        return idx + 1, x1, x2\n",
    "\n",
    "    # Run the loop\n",
    "    idx = 0\n",
    "    cond = lambda i, *_: i < (length + n_c)\n",
    "    idx, x1, x2 = tf.while_loop(cond, body, [idx, x1, x2])\n",
    "\n",
    "    # Compute c = x1[n_c:n_c+length] + x2[n_c:n_c+length] mod 2\n",
    "    c = tf.TensorArray(dtype=tf.int32, size=length)\n",
    "    for i in range(length):\n",
    "        val = tf.bitwise.bitwise_and(x1.read(i + n_c) + x2.read(i + n_c), 1)\n",
    "        c = c.write(i, val)\n",
    "\n",
    "    return c.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b0febf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(\n",
    "    input_signature=[\n",
    "        tf.TensorSpec([], tf.int32),\n",
    "        tf.TensorSpec([], tf.int32)\n",
    "    ],\n",
    "    jit_compile=True)\n",
    "def generate_prng_seq_tf_2(length, c_init):\n",
    "    n_seq = 31\n",
    "    n_c = 1600\n",
    "    total_len = length + n_c + n_seq\n",
    "\n",
    "    # Convert c_init to 31-bit tensor (LSB first)\n",
    "    c_init_bits = tf.bitwise.bitwise_and(\n",
    "        tf.bitwise.right_shift(c_init, tf.range(n_seq, dtype=tf.int32)),\n",
    "        1\n",
    "    )\n",
    "\n",
    "    # 1. Chuẩn bị mảng ban đầu\n",
    "    x1_init = tf.concat([\n",
    "        tf.constant([1], dtype=tf.int32),\n",
    "        tf.zeros(n_seq - 1, dtype=tf.int32),\n",
    "        tf.zeros(total_len - n_seq, dtype=tf.int32)\n",
    "    ], axis=0)\n",
    "\n",
    "    x2_init = tf.concat([\n",
    "        c_init_bits,\n",
    "        tf.zeros(total_len - n_seq, dtype=tf.int32)\n",
    "    ], axis=0)\n",
    "\n",
    "    # 2. Khởi tạo TensorArray bằng unstack\n",
    "    x1 = tf.TensorArray(dtype=tf.int32, size=total_len, clear_after_read=False)\n",
    "    x1 = x1.unstack(x1_init)\n",
    "\n",
    "    x2 = tf.TensorArray(dtype=tf.int32, size=total_len, clear_after_read=False)\n",
    "    x2 = x2.unstack(x2_init)\n",
    "\n",
    "    # Define the loop body\n",
    "    def body(idx, x1, x2):\n",
    "        # Cache các giá trị\n",
    "        x1_i = x1.read(idx)\n",
    "        x1_i3 = x1.read(idx + 3)\n",
    "        x1_val = tf.bitwise.bitwise_xor(x1_i, x1_i3)\n",
    "\n",
    "        x2_0 = x2.read(idx)\n",
    "        x2_1 = x2.read(idx + 1)\n",
    "        x2_2 = x2.read(idx + 2)\n",
    "        x2_3 = x2.read(idx + 3)\n",
    "        x2_val = tf.bitwise.bitwise_xor(\n",
    "            tf.bitwise.bitwise_xor(x2_0, x2_1),\n",
    "            tf.bitwise.bitwise_xor(x2_2, x2_3)\n",
    "        )\n",
    "\n",
    "        x1 = x1.write(idx + n_seq, x1_val)\n",
    "        x2 = x2.write(idx + n_seq, x2_val)\n",
    "        return idx + 1, x1, x2\n",
    "\n",
    "    # Run the loop\n",
    "    idx = 0\n",
    "    cond = lambda i, *_: i < (length + n_c)\n",
    "    idx, x1, x2 = tf.while_loop(cond, body, [idx, x1, x2])\n",
    "\n",
    "    c = tf.TensorArray(dtype=tf.int32, size=length)\n",
    "    for i in range(length):\n",
    "        x1_inc = x1.read(i + n_c)\n",
    "        x2_inc = x2.read(i + n_c)\n",
    "        val = tf.bitwise.bitwise_xor(x1_inc, x2_inc)\n",
    "        c = c.write(i, val)\n",
    "\n",
    "    return c.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01b37f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prng_seq(length, c_init):\n",
    "    r\"\"\"Implements pseudo-random sequence generator as defined in Sec. 5.2.1\n",
    "    in [3GPP38211]_ based on a length-31 Gold sequence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    length: `int`\n",
    "        Desired output sequence length\n",
    "\n",
    "    c_init: `int`\n",
    "        Initialization sequence of the PRNG. Must be in the range of 0 to\n",
    "        :math:`2^{32}-1`.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    :[``length``], `ndarray` of 0s and 1s\n",
    "        Containing the scrambling sequence\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    The initialization sequence ``c_init`` is application specific and is\n",
    "    usually provided be higher layer protocols.\n",
    "    \"\"\"\n",
    "\n",
    "    # check inputs for consistency\n",
    "    assert(length%1==0), \"length must be a positive integer.\"\n",
    "    length = int(length)\n",
    "    assert(length>0), \"length must be a positive integer.\"\n",
    "\n",
    "    assert(c_init%1==0), \"c_init must be integer.\"\n",
    "    c_init = int(c_init)\n",
    "    assert(c_init<2**32), \"c_init must be in [0, 2^32-1].\"\n",
    "    assert(c_init>=0), \"c_init must be in [0, 2^32-1].\"\n",
    "\n",
    "    # internal parameters\n",
    "    n_seq = 31 # length of gold sequence\n",
    "    n_c = 1600 # defined in 5.2.1 in 38.211\n",
    "\n",
    "    # init sequences\n",
    "    c = np.zeros(length)\n",
    "    x1 = np.zeros(length + n_c + n_seq)\n",
    "    x2 = np.zeros(length + n_c + n_seq)\n",
    "\n",
    "    #int2bin\n",
    "    bin_ = format(c_init, f'0{n_seq}b')\n",
    "    c_init = [int(x) for x in bin_[-n_seq:]] if n_seq else []\n",
    "    c_init = np.flip(c_init) # reverse order\n",
    "    # init x1 and x2\n",
    "    x1[0] = 1\n",
    "    x2[0:n_seq] = c_init\n",
    "\n",
    "\n",
    "    # and run the generator\n",
    "    for idx in range(length + n_c):\n",
    "        x1[idx+31] = np.mod(x1[idx+3] + x1[idx], 2)\n",
    "        x2[idx+31] = np.mod(x2[idx+3] + x2[idx+2] + x2[idx+1] + x2[idx], 2)\n",
    "\n",
    "    # update output sequence\n",
    "    for idx in range(length):\n",
    "        c[idx] = np.mod(x1[idx+n_c] + x2[idx+n_c], 2)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c506cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0],\n",
       "       dtype=int32),\n",
       " array([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0],\n",
       "       dtype=int32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_prng_seq_tf_2(44, 1000).numpy(), generate_prng_seq_tf(44, 1000).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7246fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 3000, time = 0.234441 s\n",
      "i = 3000, time = 0.004801 s\n",
      "i = 3000, time = 0.155830 s\n",
      "i = 3000, time = 0.002451 s\n",
      "================================\n",
      "i = 3001, time = 0.002427 s\n",
      "i = 3001, time = 0.002217 s\n",
      "i = 3001, time = 0.002474 s\n",
      "i = 3001, time = 0.002552 s\n",
      "================================\n",
      "i = 3002, time = 0.002433 s\n",
      "i = 3002, time = 0.002289 s\n",
      "i = 3002, time = 0.002233 s\n",
      "i = 3002, time = 0.002212 s\n",
      "================================\n",
      "i = 3003, time = 0.002299 s\n",
      "i = 3003, time = 0.002123 s\n",
      "i = 3003, time = 0.002171 s\n",
      "i = 3003, time = 0.002099 s\n",
      "================================\n",
      "i = 3004, time = 0.002181 s\n",
      "i = 3004, time = 0.002078 s\n",
      "i = 3004, time = 0.002090 s\n",
      "i = 3004, time = 0.002072 s\n",
      "================================\n",
      "i = 3005, time = 0.002923 s\n",
      "i = 3005, time = 0.003832 s\n",
      "i = 3005, time = 0.002491 s\n",
      "i = 3005, time = 0.002345 s\n",
      "================================\n",
      "i = 3006, time = 0.003984 s\n",
      "i = 3006, time = 0.002340 s\n",
      "i = 3006, time = 0.002190 s\n",
      "i = 3006, time = 0.002218 s\n",
      "================================\n",
      "i = 3007, time = 0.002217 s\n",
      "i = 3007, time = 0.002111 s\n",
      "i = 3007, time = 0.002102 s\n",
      "i = 3007, time = 0.002144 s\n",
      "================================\n",
      "i = 3008, time = 0.002190 s\n",
      "i = 3008, time = 0.002173 s\n",
      "i = 3008, time = 0.002299 s\n",
      "i = 3008, time = 0.002187 s\n",
      "================================\n",
      "i = 3009, time = 0.002275 s\n",
      "i = 3009, time = 0.003283 s\n",
      "i = 3009, time = 0.005159 s\n",
      "i = 3009, time = 0.003649 s\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "for i in range(3000,3010):\n",
    "    t = timeit.timeit(lambda: generate_prng_seq_tf(1200, i), number=1)\n",
    "    print(f\"i = {i}, time = {t:.6f} s\")\n",
    "    t = timeit.timeit(lambda: generate_prng_seq_tf(1200, i), number=1)\n",
    "    print(f\"i = {i}, time = {t:.6f} s\")\n",
    "    t = timeit.timeit(lambda: generate_prng_seq_tf_2(1200, i), number=1)\n",
    "    print(f\"i = {i}, time = {t:.6f} s\")\n",
    "    t = timeit.timeit(lambda: generate_prng_seq_tf_2(1200, i), number=1)\n",
    "    print(f\"i = {i}, time = {t:.6f} s\")\n",
    "    print(\"=\"*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d60cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.46 ms ± 51.5 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_prng_seq_tf(96, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "48e1e349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 ms ± 46.4 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_prng_seq_tf_2(96, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "31a26c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.18 ms ± 342 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_prng_seq(34, 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a329ffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n",
      "0.0 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000,2050):\n",
    "    print(np.var(generate_prng_seq_tf(96, i).numpy() - generate_prng_seq(96, i)), end=\" \")\n",
    "    print(np.var(generate_prng_seq_tf_2(96, i).numpy() - generate_prng_seq(96, i)), end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82df86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoader:\n",
    "    def __init__(self, shards_dir, batch_size=64, shuffle_buffer_size=10000, return_request=None):\n",
    "        if return_request is None:\n",
    "            return_request = {\n",
    "                'b': tf.float32,\n",
    "                'c': tf.float32,\n",
    "                'y': tf.complex64,\n",
    "                'x': tf.complex64,\n",
    "                'r': tf.complex64,\n",
    "                'h': tf.complex64,\n",
    "                # 'rnti': tf.int32,\n",
    "                # 'slot_num': tf.int32,\n",
    "                # 'pci': tf.int32,\n",
    "                # 'rb_start': tf.int32,\n",
    "                # 'snr': tf.float32\n",
    "            }\n",
    "        \n",
    "        self.shards_dir = shards_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle_buffer_size = shuffle_buffer_size\n",
    "        self.return_request = return_request\n",
    "        self.dataset = self._load_data()\n",
    "\n",
    "    def _parse_tfrecord_fn(self, example_proto):\n",
    "        feature_description = {item_name: tf.io.FixedLenFeature([], tf.string) for item_name in self.return_request.keys()}\n",
    "        parsed_tmp = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        parsed = {item_name: tf.io.parse_tensor(parsed_tmp[item_name], out_type=item_type) \n",
    "                  for item_name, item_type in self.return_request.items()}\n",
    "        return parsed\n",
    "\n",
    "    def _load_data(self):\n",
    "        file_pattern = os.path.join(self.shards_dir, \"*.tfrecord\")\n",
    "        dataset = tf.data.Dataset.list_files(file_pattern, shuffle=True)\n",
    "\n",
    "        dataset = dataset.interleave(\n",
    "            lambda filename: tf.data.TFRecordDataset(filename),\n",
    "            cycle_length=tf.data.AUTOTUNE,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "        dataset = dataset.map(self._parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(self.shuffle_buffer_size)\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        dataset = dataset.cache()\n",
    "        return dataset\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return self.dataset\n",
    "\n",
    "    def take(self, num_batches):\n",
    "        return self.dataset.take(num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38295202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo DataLoader\n",
    "data_loader = MyLoader(shards_dir='tfrecords', batch_size=1)\n",
    "\n",
    "# Lấy dataset từ DataLoader\n",
    "ds = data_loader.get_dataset()\n",
    "\n",
    "# Duyệt thử với update_fn\n",
    "clone3 = my_simulator.clone()\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def update_fn(rnti, slot_num, pci, rb_start):\n",
    "    clone3.update(rnti=rnti,\n",
    "                  slot_num=slot_num,\n",
    "                  pci=pci,\n",
    "                  rb_start=rb_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8101483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b (1, 1, 808)\n",
      "c (1, 1, 1, 14, 276, 2)\n",
      "y (1, 1, 4, 14, 276)\n",
      "x (1, 1, 1, 14, 276)\n",
      "r (1, 1, 1, 14, 276)\n",
      "h (1, 1, 4, 1, 1, 14, 276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 04:45:38.292083: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_84399/1755984049.py\", line 12, in update_fn  *\n        clone3.update(rnti=rnti,\n    File \"/workspaces/dsp/notebook/../src/my_simulator.py\", line 177, in update  *\n        self.tbEnc.scrambler.c_init = pusch_config._scb_c_init\n    File \"/workspaces/dsp/notebook/../src/my_encoder.py\", line 356, in c_init\n        self.sequence = self._generate_scrambling(self._input_shape)\n    File \"/workspaces/dsp/.venv/lib/python3.10/site-packages/sionna/phy/fec/scrambling.py\", line 416, in _generate_scrambling\n        seq = generate_prng_seq(input_shape[-1], self._c_init[0])\n\n    TypeError: 'NoneType' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;28mprint\u001b[39m(key, value)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mupdate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnti\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mslot_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpci\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mrb_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m h_hat, llr_det, b_hat, crc \u001b[38;5;241m=\u001b[39m clone3\u001b[38;5;241m.\u001b[39mrec(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/dsp/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filegv4_wxk4.py:8\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_fn\u001b[0;34m(rnti, slot_num, pci, rb_start)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtf__update_fn\u001b[39m(rnti, slot_num, pci, rb_start):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mFunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate_fn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mConversionOptions(recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optional_features\u001b[38;5;241m=\u001b[39m(), internal_convert_user_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;28;01mas\u001b[39;00m fscope:\n\u001b[0;32m----> 8\u001b[0m         \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone3\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrnti\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnti\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslot_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpci\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpci\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrb_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrb_start\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filetu2_1i6d.py:94\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update\u001b[0;34m(self, rnti, slot_num, pci, rb_start, verbose)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21melse_body_5\u001b[39m():\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mor_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnti\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpci\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself.tbEnc.scrambler.c_init\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_state_6\u001b[39m():\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ag__\u001b[38;5;241m.\u001b[39mldu(\u001b[38;5;28;01mlambda\u001b[39;00m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pilot_pattern\u001b[38;5;241m.\u001b[39mpilots, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself._pilot_pattern.pilots\u001b[39m\u001b[38;5;124m'\u001b[39m),)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filetu2_1i6d.py:90\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update.<locals>.if_body_5\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mif_body_5\u001b[39m():\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtbEnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrambler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_init\u001b[49m \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(pusch_config)\u001b[38;5;241m.\u001b[39m_scb_c_init\n",
      "File \u001b[0;32m/workspaces/dsp/notebook/../src/my_encoder.py:356\u001b[0m, in \u001b[0;36mMyTB5GScrambler.c_init\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    354\u001b[0m     v \u001b[38;5;241m=\u001b[39m [v]\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_init \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_scrambling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/dsp/.venv/lib/python3.10/site-packages/sionna/phy/fec/scrambling.py:416\u001b[0m, in \u001b[0;36mTB5GScrambler._generate_scrambling\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_scrambling\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape):\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns random sequence of `0`s and `1`s following\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    [3GPPTS38211_scr]_ .\"\"\"\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m     seq \u001b[38;5;241m=\u001b[39m generate_prng_seq(\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_init[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    417\u001b[0m     seq \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(seq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrdtype) \u001b[38;5;66;03m# enable flexible dtypes\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     seq \u001b[38;5;241m=\u001b[39m expand_to_rank(seq, \u001b[38;5;28mlen\u001b[39m(input_shape), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_84399/1755984049.py\", line 12, in update_fn  *\n        clone3.update(rnti=rnti,\n    File \"/workspaces/dsp/notebook/../src/my_simulator.py\", line 177, in update  *\n        self.tbEnc.scrambler.c_init = pusch_config._scb_c_init\n    File \"/workspaces/dsp/notebook/../src/my_encoder.py\", line 356, in c_init\n        self.sequence = self._generate_scrambling(self._input_shape)\n    File \"/workspaces/dsp/.venv/lib/python3.10/site-packages/sionna/phy/fec/scrambling.py\", line 416, in _generate_scrambling\n        seq = generate_prng_seq(input_shape[-1], self._c_init[0])\n\n    TypeError: 'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "for batch in ds.take(10):\n",
    "    for key, value in batch.items():\n",
    "        if len(value.shape) == 1: print(key, value)\n",
    "        else: print(key, value.shape)\n",
    "\n",
    "    update_fn(rnti=123+7*0,\n",
    "                        slot_num=5,\n",
    "                        pci=1+0,\n",
    "                        rb_start=12)\n",
    "\n",
    "    h_hat, llr_det, b_hat, crc = clone3.rec(batch[\"y\"])\n",
    "    print(f\"-----{crc}-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
